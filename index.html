<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LUNA</title>
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
  <header>
    <h1>LUNA: Low-Light Robust Panoptic Lifting for Adverse Robotic 3D Scene Perception</h1>
    <p class="authors">
      <a href="#">Ahalya Ravendran</a>, 
      <a href="#">Leo Lebrat</a>, 
      <a href="#">Rodrigo Santa Cruz</a>, 
      <a href="#">Hu Zhang</a>, 
      <a href="#">Lars Petersson</a>, 
      <a href="#">Dadong Wang</a>, 
      <a href="#">Xun Li</a>
    </p>
    <p class="affiliation">CSIRO Data61</p>
    <div class="buttons">
      <a href="https://ieeexplore.ieee.org/xpl/conhome/1001512/all-proceedings" class="btn" target="_blank">ðŸ“„ Paper</a>
      <a href="https://github.com/emev-zeno/luna/" class="btn" target="_blank">ðŸ’» Code</a>
    </div>
  </header>

  <!-- Abstract -->
  <section id="abstract">
    <h2 class="section-title">Abstract</h2>
    <p class="abstract-text">
      Robotic vision in low-light settings suffers from noise and blur, which hinder reliable scene understanding. LUNA is a geometry-aware extension of the panoptic lifting framework designed to address these challenges. By integrating depth cues with fast adaptive multitask optimization, LUNA delivers robust 3D panoptic segmentation and reconstruction even under degraded visual conditions. Tested on a systematically corrupted Replica dataset, LUNA consistently outperforms both baseline methods and restoration-augmented pipelines across varying levels of image quality.
  <!-- Methodology -->
  <section id="method">
    <h2 class="section-title">Methodology</h2>
    <div class="method-block">
      <img src="images/depth-pipeline.png" alt="Pipeline Figure" class="pipeline-img">
      <p class="method-text">
        <b>Overview of the LUNA framework.</b>  Multi-view low-quality RGB images are processed by a volumetric renderer (TensoRF) and a Mask2Former head. Geometry-aware supervision guides training via composite depth loss, while Fast Adaptive Multitask Optimization dynamically balances photometric, geometric, semantic, and instance losses.
      </p>
    </div>
  </section>

  <!-- Experiments -->
  <section id="experiments">
    <h2 class="section-title">Experiments</h2>

    <!-- Noise Query -->
    <div class="experiment-block">
      <h3 class="exp-title">Panoptic Segmentation on Original Replica Dataset</h3>
      <div class="gif-container">
        <figure>
          <img src="images/original.gif" alt="Original">
          <figcaption></figcaption>
        </figure>
      </div>
    </div>

        <!-- Blur Query -->
    <div class="experiment-block">
      <h3 class="exp-title">Panoptic Segmentation under Strong Motion Blur</h3>
      <div class="gif-container">
        <figure>
          <img src="images/pano-blur.gif" alt="Pano Blur">
          <figcaption>Panoptic Lifting</figcaption>
        </figure>
        <figure>
          <img src="images/ours-blur.gif" alt="Ours Blur">
          <figcaption>Ours</figcaption>
        </figure>
      </div>
    </div>

      <!-- Descriptive Query -->
    <div class="experiment-block">
      <h3 class="exp-title">Panoptic Segmentation under Strong Gaussian Noise</h3>
      <div class="gif-container">
        <figure>
          <img src="images/pano-noise.gif" alt="Pano Noise">
          <figcaption>Panoptic Lifting</figcaption>
        </figure>
        <figure>
          <img src="images/ours-blur.gif" alt="Ours Noise">
          <figcaption>Ours</figcaption>
        </figure>
      </div>
    </div>
  </section>

      <!-- Affordance Query -->
    <div class="experiment-block">
      <h3 class="exp-title">Recommendations for Robotic Deployment</h3>
      <p class="query-caption">"Test"</p>
      <div class="gif-container">
        <figure>
          <img src="images/lerf-lamp.gif" alt="LERF Affordance">
          <figcaption>LERF</figcaption>
        </figure>
        <figure>
          <img src="images/intent-lamp.gif" alt="Ours Affordance">
          <figcaption>Ours</figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- BibTeX -->
  <section id="bibtex">
    <h2 class="section-title">BibTeX</h2>
    <pre class="bibtex-block">
@article{ravendran2025intentfuse,
  title={IntentFuse: Language-Guided 3D Scene Understanding via Prompt Filtering and Fusion},
  author={Ravendran, Ahalya and Perera, Madhawa and Xu, Feng and Petersson, Lars and Wang, Dadong and Li, Xun},
  journal={International Conference on Digital Image Computing: Techniques and Applications},
  year={2025}
}
    </pre>
  </section>

  <script src="js/script.js"></script>
</body>
</html>
